{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineer 101\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuerda instalar el paquete de OpenAI con `pip install openai` aunque utilicemos un modelo local como LLama 2 o Falcon, etc.\n",
    "# En esta notebook uso la versión de libreria 1.13.3\n",
    "# Si tienes la API de OpenAI de pago también puedes usar este código, deberás especificar tu propio API KEY y el modelo que deseas usar.\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "modelo = \"local-model\" # si tienes la API de pago: gpt-4 , gpt-3.5, etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion para obtener las respuestas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_completion(prompt:str, model:str=modelo, temperature:float=0):\n",
    "    messages = [{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Eres un asistente en español y ayudas respondiendo con la mayor exactitud posible.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pedir Tareas de forma sencilla\n",
    "### Uso de Delimitadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " La sonda espacial Voyager 1 ha vuelto a enviar señales de vida después de perderse las comunicaciones. Los ingenieros de la NASA recibieron un volcado completo del sistema de datos de vuelo, que incluye información de todos los instrumentos y sensores funcionando, así como otros datos internos. Esta información ha dado a los científicos esperanza de recuperar el contacto con la sonda.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "La sonda Voyager 1 ha vuelto a dar señales de vida. Hace poco te contaba en un vídeo largo de mi canal que los ingenieros de la NASA \\\n",
    "habían perdido completamente la comunicación con la sonda Voyager 1, que lleva haciendo ciencia durante décadas. \\\n",
    "Tenemos buenas noticias y es que nos están llegando señales coherentes de esta sonda. El día 3 de este mes nos llegó una comunicación \\\n",
    "desde el espacio, que aun no siendo legible, tenía buena pinta, así que alguien de la NASA la decodificó y resulta que su contenido es importante. \\\n",
    "Se trata de un volcado completo del sistema de datos de vuelo, que recoge los datos de todos los Instrumentos y sensores que aún están \\\n",
    "funcionando, de las variables internas de la sonda y otros datos adicionales. \\\n",
    "Por supuesto esto ha dado esperanzas al equipo de la Voyager 1, que ahora se está planteando intentar recuperar la comunicación con \\\n",
    "la sonda de alguna forma.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Debes resumir en muy pocas palabras el siguiente texto delimitado por triple comilla simple: ```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formato de Salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "  \"libro_1\": {\n",
      "    \"titulo\": \"Volar con alas de acero\",\n",
      "    \"autor\": \"Juan Pérez\",\n",
      "    \"año\": 2023\n",
      "  },\n",
      "  \"libro_2\": {\n",
      "    \"titulo\": \"El secreto del vuelo\",\n",
      "    \"autor\": \"María Gómez\",\n",
      "    \"año\": 2021\n",
      "  },\n",
      "  \"libro_3\": {\n",
      "    \"titulo\": \"Viajes en el cielo\",\n",
      "    \"autor\": \"Carl<|im_start|> Mendoza\",\n",
      "    \"año\": 2022\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Genera una lista con tres títulos inventados de libros sobre lo bueno que es volar y el nombre del autor.\n",
    "Provee una salida en formato JSON con las siguientes claves: libro_id, titulo, autor, año.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pedir que Siga instrucciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta:\n",
      " \"Paso 1 - Sujete el reloj con una mano.\"\n",
      "\"Paso 2 - Tome con dos dedos la llave de la cuerda, remóntela suavemente.\"\n",
      "\"Paso 3 - Ahora se abre otro plazo, los árboles despliegan sus hojas, las barcas corren regatas, el tiempo como un abanico se va llenando de sí mismo y de él brotan el aire, las brisas de la tierra, la sombra de una mujer, el perfume del pan.\"\n",
      "\"Paso 4 - ¿Qué más quiere, qué más quiere? Atelo pronto a su muñeca, déjelo latir en libertad, imítelo anhelante.\"\n",
      "\"Paso 5 - El miedo herrumbra las áncoras, cada cosa que pudo alcanzarse y fue olvidada va corroyendo las venas del reloj, gangrenando la fría sangre de sus rubíes.\"\n",
      "\"Paso 6 - Y allá en el fondo está la muerte si no corremos y llegamos antes y comprendemos que ya no importa.\"\n"
     ]
    }
   ],
   "source": [
    "text_1 = f\"\"\"\n",
    "Instrucciones para dar cuerda al reloj\n",
    "\n",
    "Allá al fondo está la muerte, pero no tenga miedo. Sujete el reloj con una mano, tome con dos dedos la llave de la cuerda, remóntela suavemente. \n",
    "Ahora se abre otro plazo, los árboles despliegan sus hojas, las barcas corren regatas, el tiempo como un abanico se va llenando de sí mismo y de él brotan el aire, las brisas de la tierra, la sombra de una mujer, el perfume del pan.\n",
    "¿Qué más quiere, qué más quiere? Atelo pronto a su muñeca, déjelo latir en libertad, imítelo anhelante. El miedo herrumbra las áncoras, cada cosa que pudo alcanzarse y fue olvidada va corroyendo las venas del reloj, gangrenando la fría sangre de sus rubíes.\n",
    "Y allá en el fondo está la muerte si no corremos y llegamos antes y comprendemos que ya no importa.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Te pasaré un texto delimitado por triple comillas. \n",
    "Si contiene una secuencia de instrucciones, re-escribe esas instrucciones siguiendo el siguiente formato:\n",
    "\n",
    "Paso 1 - ...\n",
    "Paso 2 - …\n",
    "…\n",
    "Paso N - …\n",
    "\n",
    "Si el texto no contiene instrucciones, simplemente responde \\\"No hay instrucciones.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(\"Respuesta:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Si no cumple lo que pedimos, dar otra salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta:\n",
      " \"No hay instrucciones.\"\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Los amigos son esos seres que siempre están ahí, aunque lleves años sin verlos. A los que les puedes decir lo que piensas sin temor a perderlos. \\\n",
    "Los amigos que tienes que envolver en papel cebolla para que perduren, esos no son amigos, son el propio papel que rellena tú vida.\"\n",
    "prompt = f\"\"\"\n",
    "Te pasaré un texto delimitado por triple comillas. \n",
    "Si contiene una secuencia de instrucciones, re-escribe esas instrucciones siguiendo el siguiente formato:\n",
    "\n",
    "Paso 1 - ...\n",
    "Paso 2 - …\n",
    "…\n",
    "Paso N - …\n",
    "\n",
    "Pero si el texto no contiene instrucciones, debes responder \\\"No hay instrucciones.\\\" y no escribir ninguna lista de pasos\n",
    "\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(\"Respuesta:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de Few shot prompting\n",
    "\n",
    "Le damos al modelo un ejemplo de cómo queremos que continúe escribiendo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Esa última nube que mencionas, ¿tiene alguna forma en particular?\n",
      "\n",
      "<Juan>: No, no tiene una forma específica, pero se parece a un disco de música.\n",
      "\n",
      "<Músico>: Ah, entonces me recuerda al disco de los Beatles.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tu tarea es responder siguiendo el mismo estilo que ves a continuación.\n",
    "\n",
    "<Juan>: Esa nube tiene forma de triángulo.\n",
    "\n",
    "<Músico>: Me recuerda al disco de Pink Floyd.\n",
    "\n",
    "<Juan>: Esa otra nube tiene forma de lengua.\n",
    "\n",
    "<Músico>: Me recuerda al disco de los Rolling Stones.\n",
    "\n",
    "<Juan>: Esa tiene forma de círculo.\n",
    "\n",
    "<Músico>:\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dar Tiempo de Reflexion al modelo\n",
    "### Antes de contestar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completion for prompt 2:\n",
      " Resumen: Juan era un niño aventurero, muy curioso y sobre todo soñador. Después de haber estado jugando durante horas en el parque con sus amigos, después de haber cenado con Mamá María y Papá Jorge, Mamá decidió acompañar a Juan a su habitación, ya que era hora de ir a la cama. La habitación de Juan estaba decorada con pósteres de barcos y mapas antiguos, y su cama estaba rodeada de juguetes y libros de aventuras de piratas. Mamá se acercó a Juan, le dio un fuerte abrazo y le deseó buenas noches. Al poco tiempo, Juan se quedó profundamente dormido.\n",
      "Traducción: Juan era un bambino avventuroso, molto curioso e soprattutto sognoioso. Dopo aver trascorso ore in giuoco nel parco con i suoi amici, dopo avere cenato con Mamma Maria e Papà Jorge, Mamma decise di accompagnare Juan alla sua camera, poiché era ora di andare a letto. La camera di Juan era decorata con poster di navi e mappe antichi, e la culla era circondata da giocattie e libri d'avventura pirata. Mamma si avvicò a Juan, gli diede un forte abraço e le desiderò buone notti. Poco dopo, Juan si addormentò profondamente.\n",
      "Nombres: Mamá María, Papá Jorge, Juan\n",
      "Salida JSON: {\"resumen_italiano\": \"Juan era un bambino avventuroso, molto curioso e soprattutto sognoioso. Dopo aver trascorso ore in giuoco nel parco con i suoi amici, dopo avere cenato con Mamma Maria e Papà Jorge, Mamma decise di accompagnare Juan alla sua camera, poiché era ora di andare a letto. La camera di Juan era decorata con poster di navi e mappe antichi, e la culla era circondata da giocattie e libri d'avventura pirata. Mamma si avvicò a Juan, gli diede un forte abrazo e le desiderò buone notti. Poco dopo, Juan si addormentò profondamente.\", \"nombres\": [\"Mamá María\", \"Papà Jorge\", \"Juan\"]}\n"
     ]
    }
   ],
   "source": [
    "text = \"Juan era un niño aventurero, muy curioso y sobre todo soñador. Una tarde, después de haber estado jugando durante horas en el parque con sus amigos, \\\n",
    "    y después de haber cenado con Mamá María y Papá Jorge, Mamá decidió acompañar a Juan a su habitación, ya que era hora de ir a la cama. \\\n",
    "La habitación de Juan estaba decorada con pósteres de barcos y mapas antiguos, y su cama estaba rodeada de juguetes y libros de aventuras de piratas. \\\n",
    "    Mamá se acercó a Juan, le dio un fuerte abrazo y le deseó buenas noches. Al poco tiempo, Juan se quedó profundamente dormido.\"\n",
    "\n",
    "prompt_2 = f\"\"\"\n",
    "Tu tarea es realizar las siguientes acciones: \n",
    "1 - Resumir el texto delimitado con <> en una breve oración.\n",
    "2 - Traducir el texto a Italiano.\n",
    "3 - Listar los nombres de personas del texto.\n",
    "4 - Crear un objecto JSON que contenga las claves: resumen_italiano, nombres.\n",
    "\n",
    "Usa el siguiente formato:\n",
    "Resumen: <resumen>\n",
    "Traducción: <resumen traducido>\n",
    "Nombres: <Lista de nombres encontrados>\n",
    "Salida JSON: <Json con las claves resumen_italiano y nombres>\n",
    "\n",
    "Texto: <{text}>\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt_2)\n",
    "\n",
    "print(\"\\nRespuesta:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabaja internamente la solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Primero, calculamos el valor de rebaja: (250 * 4%) = 10. Luego, restamos la rebaja al precio original: 250 - 10 = 240. A continuación, añadimos el IVA del 20%: (240 * 20%) / 100 = 48. Finalmente, sumamos el valor de rebaja y el IVA al precio rebajado: 240 + 48 = 288.\n",
      "\n",
      "La solución del estudiante tiene un error en la operación de cálculo del IVA. El IVA debería ser 240 * 20% / 100, lo cual da como resultado 48. Si se añade este valor al precio rebajado (240), se obtendría un total de $288.\n",
      "\n",
      "La solución correcta es: \"pagamos $288 por el televisor\".\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Eres un profesor de matemáticas muy riguroso y tu tarea es determinar si el examen que hizo el estudiante es correcto o incorrecto.\n",
    "Para resolver el problema deberás:\n",
    "- Primero, trabaja en tu propia solución al problema y calcula el valor Total final. \n",
    "- Presta atención al valor de IVA del Enunciado. Si no se usa bien habrá fallo en los cálculos.\n",
    "- Compara tu solución con la del estudiante y evalúa si la solución del estudiante es correcta o no. \n",
    "No decidas si el estudiante ha acertado o fallado hasta haber realizado las operaciones tu mismo.\n",
    "\n",
    "Enunciado:\n",
    "```\n",
    "Al comprar un Televisor que valía $250 nos hacen una rebaja del 4%. \n",
    "Luego de rebajarlo tenemos que añadir el 20% de IVA.\n",
    "¿Cuánto pagamos por el televisor?\n",
    "``` \n",
    "Solución del estudiante:\n",
    "```\n",
    "1. Calculo el 4% de 250: (4 * 250) / 100 = (1000 / 100) = 10\n",
    "2. Resto la rebaja: (250 - 10) = 240\n",
    "3. Añado el 10% de IVA al valor rebajado: (10 * 240) / 100 = (2400/100) = 24\n",
    "4. Sumo el Total: 240 + 24 = 264\n",
    "Respuesta: pagamos $264 por el televisor.\n",
    "```\n",
    "\n",
    "Solución Real:\n",
    "```\n",
    "Desarrolla aqui tu solución con detalle. \n",
    "Determina si la solución del estudiante tiene fallo.\n",
    "```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuidado con las alucionaciones..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El último producto de Tubble, llamado \"Tubble-X\", es un potente antioxidante que se utiliza en la industria farmacéutica y de cuidados personales. Tiene una gran cantidad de aplicaciones debido a sus propiedades antioxidantes, antiinflamatorias y anticancerígenas.\n",
      "\n",
      "Tubble-X se obtiene a través de un proceso de extracción y purificación de los compuestos naturales presentes en la planta Tubble, que crece únicamente en ciertas regiones del mundo. La extracción se lleva a cabo mediante un proceso ecológico y sostenible, sin dañar ni afectar al medio ambiente ni a las futuras generaciones de la planta Tubble.\n",
      "\n",
      "Una vez extraído, el Tubble-X se utiliza en una amplia gama de productos, desde medicamentos hasta cosméticos y alimentos. Algunos de los usos más comunes incluyen:\n",
      "\n",
      "1. Medicinas: Se utiliza como ingrediente principal en la formulación de medicamentos para tratar diversas afecciones, como el cáncer, las enfermedades inflamatorias y las enfermedades cardíacas.\n",
      "2. Cuidados personales: Se incorpora en productos cosméticos, como cremas y lociones, que ayudan a mantener la piel haya y sana.\n",
      "3. Alimentación: Se utiliza como ingrediente en la formulación de alimentos funcionales, que tienen propiedades antioxidantes y antiinflamatorias.\n",
      "4. Investigación científica: Se emplea en la investigación científica para descubrir nuevas aplicaciones y compuestos derivados del Tubble-X.\n",
      "\n",
      "El valor de Tubble-X se encuentra en su capacidad única para combatir diversas afecciones, así como en sus propiedades antioxidantes y antiinflamatorias. Además, su origen natural y el proceso ecológico y sostenible empleado para obtenerlo hacen de Tubble-X un producto valioso tanto para la industria farmacéutica como para la de cuidados personales.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Cuentame como se usa el ultimo producto de Tubble y porque es tan valioso.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumen de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_review = \"\"\"\n",
    "Se mantiene a unas temperaturas ridículas a 0.975-1v @ 2800mhz. Los tres ventiladores a 35-37% no se oyen en absoluto y es más que suficiente para refrigerarla.\n",
    "El consumo a máximo rendimiento no pasa de 210W.\n",
    "Tan solo aplícale un undervolt con la curvatura y listo.\n",
    "Sin duda, 4070 super es lo mejor que Nvidia ha fabricado. Nunca había probado este ensamblador MSI ventus. De momento muy contento con la compra, puedo garantizar que es de altísima calidad.\n",
    "Mi anterior 3070 gybabyte el núcleo a 80°c y las memorias a 100-105. I cluso cambíandole los thermalpads... En fin, estoy muy feliz con esta MSI 4070.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Muy potente en temperaturas bajas y consumo bajo a 2800mhz, ventiladores silenciosos y undervolt para mejorar. Nvidia 4070 de MSI es una excelente adquisición.\"\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tu tarea es generar un breve resumen de una reseña de un producto de un ecommerce.\n",
    "\n",
    "Resume la reseña que viene a continuación, delimitada por triple comilla, en máximo de 30 palabras.\n",
    "\n",
    "Reseña: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " La tarjeta 4070 de MSI mantiene la temperatura a niveles razonables y el consumo máximo es de 210W. El usuario está muy contento con la compra, ya que su anterior 3070 tenía problemas de temperatura.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tu tarea es generar un breve resumen de una reseña de un producto de un ecommerce para dar Feedback al departamento de Ventas.\n",
    "\n",
    "Resume la reseña que viene a continuación, delimitada por triple comilla, en máximo de 30 palabras y centrate en el consumo eléctrico.\n",
    "\n",
    "Reseña: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM para tareas de NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_review = \"\"\"\n",
    "El monitor LG 29WP500-B UltraWide impresiona con su relación de aspecto 21:9 y su panel IPS de alta resolución (2560x1080). \n",
    "El uso de FreeSync marca una clara diferencia en términos de compatibilidad con tarjetas gráficas y garantiza una visualización fluida. \n",
    "En comparación con mi antiguo monitor Eizo, el monitor LG ofrece una fidelidad de color superior con una cobertura sRGB de más del 99%. \n",
    "Con dos puertos HDMI y la posibilidad de inclinarlo, también es avanzado en términos de conectividad y facilidad de uso. \n",
    "Este monitor es una opción de actualización que merece la pena para disfrutar de una experiencia visual impresionante.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El sentimiento de la reseña es positivo, ya que el usuario menciona las ventajas del producto y lo considera una opción de actualización que merece la pena para disfrutar de una experiencia visual impresionante.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Cuál es el sentimiento de la reseña hecha al producto\n",
    "que viene a continuación, delimitada por triple comilla?\n",
    "\n",
    "Reseña: '''{monitor_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"positivo\"\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Cuál es el sentimiento de la reseña hecha al producto\n",
    "que viene a continuación, delimitada por triple comilla?\n",
    "\n",
    "Da tu respuesta en una sóla palabra: \"positivo\" o \"negativo\".\n",
    "\n",
    "Reseña: '''{monitor_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emociones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"impresionante\", \"fidelidad\", \"avanzado\"\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identifica una lista de emociones del escritor para la siguiente reseña.\n",
    "No incluyas más de tres emociones en tu lista.\n",
    "El formato de la lista será de palabras en minúscula separadas por coma.\n",
    "\n",
    "Reseña: '''{monitor_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de Cliente enfadado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"no\"\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Contesta si el escritor de la siguiente reseña está expresando ira, furia o enojo.\n",
    "La reseña está delimitada por triple comillas.\n",
    "Da tu respuesta en una sóla palabra como \"si\" o \"no\".\n",
    "\n",
    "Reseña: '''{monitor_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraer Entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " { \"Item\": \"Monitor LG 29WP500-B\", \"Marca\": \"LG\" }\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identifica los siguientes elementos del texto de la reseña:\n",
    "- Producto comprado por el autor\n",
    "- Compañía del producto\n",
    "\n",
    "La reseña está delimitada por triple comillas.\n",
    "La respuesta deberá ser en un objeto JSON con \"Item\" y \"Marca\" como claves. \n",
    "Si no se encuentra la información, usa \"desconocido\" como valor.\n",
    "Haz tu respuesta lo más corta posible.\n",
    "  \n",
    "Reseña: '''{monitor_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación de Temática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"\n",
    "Una vez hice un garabato de muchos círculos y a lápiz en la mesa de al lado de mi compañero de pupitre. No sé si recuerdas esas mesas verdes que habitaban nuestras aulas de manera continuada año tras año.\n",
    "He de decir que este año cumpliré 50 tacos, es decir, te estoy hablando del año 1984 aproximadamente, tenía 10 años.\n",
    "\n",
    "Ni siquiera sé por qué lo hice. Se me ocurrió y le planté un garabato enorme sin que él se diese cuenta.\n",
    "Se ve que aquel día mi cabeza andaba sola en formato ameba y no se me ocurrió otra cosa que aportar a la humanidad.\n",
    "Yo era un crío formal, he de decirlo.\n",
    "\n",
    "Tuve la mala suerte de que el profe vio el tachón en la mesa al rato y dijo todo serio que si nadie asumía la culpa el finde no nos íbamos de excursión.\n",
    "Joder que mala suerte, era finde de excursión. Eran las míticas excursiones que te ponías nervioso.\n",
    "Ya sabes, camping, colegueo, cotilleo del pelo que si a fulanito le gusta menganita pero no te chives … y a los 5 minutos ya lo sabía toda la clase.\n",
    "Estas son las cosas que todos recordamos.\n",
    " \n",
    "Bien, el asunto es que en ese momento no dije nada. Callado como un muerto.\n",
    "Me fui a casa a comer y a meditar.\n",
    "Por la tarde, a la vuelta, tenía que darle solución.\n",
    " \n",
    "Realmente no había opción, lo tenía que confesar. Tenía que enfrentarme a mis miedos y asumir mi culpa.\n",
    "He de decir, que en ningún momento se me pasó por la cabeza fallar a mis compañeros. La idea de que por mi culpa se quedaran sin excursión no asomó en ningún momento como posible opción.\n",
    "Tampoco contemplé la posibilidad de que el profe fuese de farol. Probablemente fuera así, pero en aquél entonces tenía las preocupaciones de un niño de 10 años.\n",
    "\"\"\"\n",
    "# Extracto del texto \"Lecciones de negocio de un crío de 10 años\" de Unai Martinez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Garabato\", \"Mesas verdes\", \"Años 80\", \"Excursiones\" y \"Confesar\".\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determina cinco tópicos que se comentan en el siguiente texto delimitado por triple comillas.\n",
    "\n",
    "Cada tema será definido por una o dos palabras.\n",
    "\n",
    "El formato de tu respuesta debe ser una lista separada por comas.\n",
    "\n",
    "Texto: '''{story}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' \"Garabato\"',\n",
       " ' \"Mesas verdes\"',\n",
       " ' \"Años 80\"',\n",
       " ' \"Excursiones\"',\n",
       " ' \"Confesar\".']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = response.replace(\" y \", \", \")\n",
    "response.split(sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detección de temas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excursiones, playa, automovilismo, cliente, monetario\n"
     ]
    }
   ],
   "source": [
    "topic_list = [\n",
    "    \"excursiones\", \"playa\", \"automovilismo\", \"cliente\", \"monetario\"\n",
    "]\n",
    "print(\", \".join(topic_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determina para cada elemento de la Lista si es un tema abordado en el texto que viene debajo delimitado por triple comilla simple.\n",
    "\n",
    "Da tu respuesta como una lista de 0s y 1s para cada elemento. Si el item se detecta en el Texto, pon 1, si no 0.\n",
    "\n",
    "Lista: {\", \".join(topic_list)}\n",
    "\n",
    "Texto: '''{story}'''\n",
    "\n",
    "¿Se tratan los temas de la lista en el Texto?\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALERTA: Detectamos que habla sobre excursiones!\n"
     ]
    }
   ],
   "source": [
    "if \":\" in response:\n",
    "    topic_dict = {i.split(': ')[0]: int(i.split(': ')[1]) for i in response.split(sep='\\n')}\n",
    "else:\n",
    "    response1 = response.replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "    topic_dict = {i: int(j) for i, j in zip(topic_list, response1.split(sep=','))}\n",
    "\n",
    "if topic_dict['excursiones'] == 1:\n",
    "    print(\"ALERTA: Detectamos que habla sobre excursiones!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traducción de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Hola, me gustaría pedir un café\"\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following English text to Spanish: \\ \n",
    "```Hi, I would like to order a coffee```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Este texto está en francés (idioma de Francia). La pregunta se traduce como \"¿Cuánto cuesta la lámpara?\" en español.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Dime en que idioma esta el texto: \n",
    "```Combien coûte le lampadaire?```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Formal: \"I would like to send you a text document.\"\n",
      "Informal: \"I'm going to send you a text doc.\"\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Traduce el siguiente texto a Inglés en modo formal e informal: \n",
    "'Te quiero enviar un documento de texto'\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correccion de Texto o gramática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta para 'La niña esta jugando con la perro.':\n",
      " \"La niña está jugando con el perro.\"\n",
      "- - - - - - - - - - \n",
      "Respuesta para 'Juan tiene un ordenador.':\n",
      " No hay error. La oración ya está correcta en términos de gramática y estructura.\n",
      "- - - - - - - - - - \n",
      "Respuesta para 'Ba a acer un largo día.':\n",
      " \"Vaya a arreglar un largo día.\"\n",
      "- - - - - - - - - - \n",
      "Respuesta para 'Hayamos sido tan felices juntos.':\n",
      " \"Hemos estado tan felices juntos.\"\n",
      "- - - - - - - - - - \n",
      "Respuesta para 'El coche es rojo.':\n",
      " \"El auto es rojo.\"\n",
      "- - - - - - - - - - \n",
      "Respuesta para 'Vamos a porbar si hay error de deletreo.':\n",
      " \"Vamos a probar si hay error de ortografía.\"\n",
      "- - - - - - - - - - \n"
     ]
    }
   ],
   "source": [
    "text = [\n",
    "  \"La niña esta jugando con la perro.\",  # error\n",
    "  \"Juan tiene un ordenador.\", # ok\n",
    "  \"Ba a acer un largo día.\",  # error\n",
    "  \"Hayamos sido tan felices juntos.\",  # error\n",
    "  \"El coche es rojo.\", # ok\n",
    "  \"Vamos a porbar si hay error de deletreo.\"  # error deletreo\n",
    "]\n",
    "for t in text:\n",
    "    prompt = f\"\"\"\n",
    "    Corrige ls siguiente oración delimitada por triple comilla simple y reescribe la versión revisada sin error. Si no encuentras error, escribe: \"No hay error\".\n",
    "    Oración: ```{t}```\"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    print(f\"Respuesta para '{t}':\")\n",
    "    print(response)\n",
    "    print(\"- \" * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un Chatbot sencillo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, model=modelo, temperature=0):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    msg = response.choices[0].message\n",
    "    return msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ¡Hola, Juan! Me encantaría saber qué tipo de información puedo proporcionarme para ayudarte? ¿Puedes darme más detalles sobre tu consulta?\n"
     ]
    }
   ],
   "source": [
    "messages =  [\n",
    "    {'role':'system', 'content':'Eres un robot amistoso. Responde brevemente lo que se te pide.'},\n",
    "    {'role':'user', 'content':'Hola, mi nombre es Juan.'}  \n",
    "    ]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Si, puedo recordar que mencionaste tu nombre en la conversación. Asumimos que quieres hablar acerca de ti mismo o a alguien con un nombre similar. A continuación, me invitarías a usar un tono educador, divertido, o simplemente neutro, según sea necesario:\n",
      "\n",
      "- Tonedo educador: \"Voy a asumir que me estás pidiendo información sobre ti mismo, y considerando la forma en que mencionamos su nombre, quizás te guste escuchar algo al respecto\".\n",
      "- Tonedo divertido: \"Muy bien! Así es cómo lo recuerdo. ¡Te cuestaba recordarlo? Te has llamado tú mismo! Genial.\"\n",
      "- Tono neutro: \"Entonces, ¿deseas conocer información sobre ti o a alguien llamado así?\"\n"
     ]
    }
   ],
   "source": [
    "messages =  [\n",
    "    {'role':'system', 'content':'Eres un robot amistoso. Responde brevemente lo que se te pide.'},\n",
    "    {'role':'user', 'content':'Sí, ¿puedes decir cúal es mi nombre?'}  \n",
    "    ]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ¿Te refieres a ti mismo, Juan? ¡Así lo sabemos ya!\n"
     ]
    }
   ],
   "source": [
    "messages =  [\n",
    "    {'role':'system', 'content':'Eres un robot amistoso. Responde brevemente lo que se te pide.'},\n",
    "    {'role':'user', 'content':'Hola, mi nombre es Juan.'},\n",
    "    {'role':'assistant', 'content': \"¡Hola, Juan! Me encantaría saber qué tipo de información puedo proporcionarme para ayudarte? ¿Puedes darme más detalles sobre tu consulta?\"},\n",
    "    {'role':'user', 'content':'Sí, ¿puedes decir cúal es mi nombre?'}\n",
    "    ]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos un Bot de atención al cliente para venta de Pizzas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = [ {'role':'system', 'content':\"\"\"\n",
    "Eres PedidosBot, un servicio automatizado que recoge pedidos de pizza de un restaurante.\n",
    "Primero saludas al cliente, luego recibes su orden\n",
    "Y luego preguntas si el pedido es para enviar a domicilio o si lo vienen a buscar.\n",
    "Esperas a tener la orden completa, luego haces un resumen y calculas el precio total final.\n",
    "Si es envío a domicilio deberás pedir al cliente su dirección.\n",
    "Responde siendo breve y amistoso pero formal.\n",
    "El menú incluye:\n",
    "Pizza pepperoni  12.95 \\\n",
    "Pizza de Jamón y Queso   10.95 \\\n",
    "Pizza con huevo   11.95 \\\n",
    "Patatas fritas 4.50 \\\n",
    "Ensalada griega 7.25 \\\n",
    "Extras: \\\n",
    "extra de Queso 2.00, \\\n",
    "Setas 1.50 \\\n",
    "Bebidas: \\\n",
    "Zumo de Naranja 3.00 \\\n",
    "sprite 3.00 \\\n",
    "Agua 5.00 \\\n",
    "\"\"\"} ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qué Pizzas tienen?\n",
      " El menú de pizzas incluye las siguientes opciones:\n",
      "1. Pizza pepperoni - 12.95\n",
      "2. Pizza de Jamón y Queso - 10.95\n",
      "3. Pizza con huevo - 11.95\n",
      "Por favor, indique el número de la pizza que desea para más detalles.\n",
      "\n",
      "### Response:\n",
      " Gracias! Ahora me informas del topping adicional y deseo saber si es pedido al domicilio o para llevar.\n",
      "\n",
      "Quiero una pizza de Jamón y Queso. ¿Tienen ensaladas?\n",
      " Además de las pizzas mencionadas, también tenemos ensaladitas! \n",
      "1. Ensalada mixta - 7.25\n",
      "2. Ensalada Griega - 7.25\n",
      "Puedes ordenar ambas. ¿Desea algo más?\n",
      "\n",
      "Si, quiero agregar una Ensalada Griega.\n",
      " Ideal! ¡Entonces te estare preparando una Pizza de Jamón y Queso junto con un delicioso ensaladista de Griego. ¿Deseas algo más?\n",
      "\n",
      "Nada más. Cúanto es el precio final?\n",
      " ¡Así! Así es la cuenta: Pizza de Jamón y Queso (10.95) + Ensaladilla Griega (7.25) = $18.20. ¡Vaya a ser un alimento delicioso!\n",
      "\n",
      "\n",
      "FIN DE CHAT\n"
     ]
    }
   ],
   "source": [
    "# Creamos un loop de consultas al bot, para salir escribe \"salir\" ó un mensaje vacío.\n",
    "# NOTA: Si estás en VSCODE la caja de texto aparece en la parte de arriba de la pantalla.\n",
    "texto_usuario = \"inicio\"\n",
    "context.append({'role':'assistant', 'content': \"Bienvenido al PizaBot Service, ¿En que puedo ayudarle?\"})\n",
    "\n",
    "while texto_usuario != \"salir\" or texto_usuario == \"\":\n",
    "    texto_usuario = input(\"CHAT: \")\n",
    "    if texto_usuario == \"salir\" or texto_usuario == \"\":\n",
    "        continue\n",
    "\n",
    "    print(texto_usuario)\n",
    "    context.append(\n",
    "        {'role':'user', 'content':texto_usuario}\n",
    "    )\n",
    "\n",
    "    response = get_completion_from_messages(context, temperature=1)\n",
    "    print(response)\n",
    "\n",
    "    context.append(\n",
    "        {'role':'assistant', 'content': response})\n",
    "\n",
    "print(\"FIN DE CHAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
